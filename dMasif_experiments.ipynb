{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ1r1bbb0yBv"
      },
      "source": [
        "#  _dMasif for ADP binding site prediction_\n",
        "\n",
        "Submission for the Geometric Deep Learning assesment, HT23.\n",
        "Candidate Number: 1045801\n",
        "\n",
        "This notebook contains a stand-alone implementation of the dMasif model for protein binding site prediction. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1AmxvNjbZhq",
        "outputId": "4e0e0999-c435-43d1-e328-8f7fb9001b22"
      },
      "outputs": [],
      "source": [
        "#@title Download dataset\n",
        "!wget https://github.com/candidate1045801/miniproject/raw/main/data.zip\n",
        "!unzip /content/data.zip\n",
        "!rm /content/data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7QYjg6Rm0kq"
      },
      "source": [
        "\n",
        "## Julia notebook installation instructions\n",
        "1. Change runtime type to use GPU acceleration\n",
        "2. Execute the following cell to install the Julia kernel together with all the necessary packages. This may take a couple of minutes.\n",
        "3. Reload this page and continue to the next section.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIeFXS0F0zww",
        "outputId": "8b452584-9a50-4e21-eff4-b447402493b6"
      },
      "outputs": [],
      "source": [
        "# Credit for this code: https://github.com/ageron/julia_notebooks\n",
        "\n",
        "# Assuming python3 runtime\n",
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.8.5\" # any version ≥ 0.7.0\n",
        "JULIA_PACKAGES=\"IJulia\"\n",
        "JULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\n",
        "JULIA_NUM_THREADS=2\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  # Install Packages\n",
        "  nvidia-smi -L &> /dev/null && export GPU=1 || export GPU=0\n",
        "  if [ $GPU -eq 1 ]; then\n",
        "    JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n",
        "  fi\n",
        "  for PKG in `echo $JULIA_PACKAGES`; do\n",
        "    echo \"Installing Julia package $PKG...\"\n",
        "    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"' &> /dev/null\n",
        "  done\n",
        "\n",
        "  # Install kernel and rename it to \"julia\"\n",
        "  echo \"Installing IJulia kernel...\"\n",
        "  julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n",
        "      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n",
        "  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n",
        "  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n",
        "  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia  \n",
        "\n",
        "  echo ''\n",
        "  echo \"Successfully installed `julia -v`!\"\n",
        "  echo \"Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\"\n",
        "  echo \"jump to the 'Check the Installation' section.\"\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "EEzvvzCl1i0F",
        "outputId": "32c9e4af-f0a7-4b13-ea5d-a2535274314b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "nothing"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Julia Version 1.8.1\n",
            "Commit afb6c60d69 (2022-09-06 15:09 UTC)\n",
            "Platform Info:\n",
            "  OS: Windows (x86_64-w64-mingw32)\n",
            "  CPU: 12 × Intel(R) Core(TM) i7-8750H CPU @ 2.20GHz\n",
            "  WORD_SIZE: 64\n",
            "  LIBM: libopenlibm\n",
            "  LLVM: libLLVM-13.0.1 (ORCJIT, skylake)\n",
            "  Threads: 4 on 12 virtual cores\n",
            "Environment:\n",
            "  JULIA_DEPOT_PATH = D:\\Programs\\julia_depot\n",
            "  JULIA_NUM_THREADS = 4"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Apr 10 20:25:11 2023       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 496.76       Driver Version: 496.76       CUDA Version: 11.5     |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|                               |                      |               MIG M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\r\n",
            "| N/A   47C    P8    N/A /  N/A |     75MiB /  4096MiB |      0%      Default |\r\n",
            "|                               |                      |                  N/A |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                                  |\r\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
            "|        ID   ID                                                   Usage      |\r\n",
            "|=============================================================================|\r\n",
            "|  No running processes found                                                 |\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Process(`\u001b[4mnvidia-smi\u001b[24m`, ProcessExited(0))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Check the installation\n",
        "display(versioninfo())\n",
        "println()\n",
        "try\n",
        "    using CUDA\n",
        "catch\n",
        "    println(\"No GPU found.\")\n",
        "else\n",
        "    run(`nvidia-smi`) \n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ENTTQf-bXl70"
      },
      "outputs": [],
      "source": [
        "# @title Import the required packages\n",
        "\n",
        "# Machine Learning\n",
        "using CUDA\n",
        "using Flux\n",
        "using OneHotArrays\n",
        "\n",
        "using IJulia\n",
        "using BenchmarkTools\n",
        "using Logging\n",
        "global_logger(ConsoleLogger())\n",
        "using LinearAlgebra\n",
        "using Distributions\n",
        "using Distances\n",
        "using Distributed\n",
        "using LogExpFunctions: logsumexp as lsumexp\n",
        "# using Plots\n",
        "\n",
        "using Random \n",
        "Random.seed!(1234);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY4jtVejPXrp"
      },
      "source": [
        "# Part 1: Generate surface data from atom data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYm-jbEp-_q4",
        "outputId": "d4a8794c-3263-4841-86d0-7d08cdf7d8ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ProteinStructure 1AE4.pdb with 1 models, 1 chains (A), 324 residues, 434 atoms"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "using BioStructures: resnameselector, collectresidues, coordarray, element, collectatoms,\n",
        "                     read, PDB, StructuralElement, standardselector\n",
        "                     \n",
        "using Bio3DView\n",
        "#@title Load input atom data\n",
        "\n",
        "adpselector(res) = resnameselector(res, [\"ADP\"])\n",
        "const ELEMENTS = [\"C\", \"H\", \"N\", \"O\", \"S\", \"SE\"]\n",
        "const ELEMENT_IDS = Dict([(ELEMENTS[i], i) for i in eachindex(ELEMENTS)])\n",
        "const RADII = [1.7, 1.1, 1.52, 1.55, 1.80, 1.90] # van der waals radii\n",
        "\n",
        "function get_atom_data(struc::StructuralElement)\n",
        "    aminoacids = collectresidues(struc, standardselector)\n",
        "    coords = coordarray(aminoacids)\n",
        "\n",
        "    types = get.(Ref(ELEMENT_IDS), element.(collectatoms(aminoacids); strip=true), 2)\n",
        "\n",
        "    adps = collectresidues(struc, adpselector)\n",
        "    adp_coords = coordarray(adps)\n",
        "\n",
        "    # hack to be able to handle proteins which don't bind to ADP\n",
        "    if isempty(adp_coords)\n",
        "        adp_coords = [1e6, 1e6, 1e6]\n",
        "    end\n",
        "    return coords, types, adp_coords\n",
        "end\n",
        "\n",
        "struc = read(\"data/1AE4.pdb\", PDB)\n",
        "coords, types, adp_coords = get_atom_data(struc)\n",
        "display(struc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "check_sdf (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Optimized sdf functions \n",
        "# low memory implementation of SDF\n",
        "# to make faster - batch it up to enable parallelism\n",
        "function sdf(x, coords, radii; ideal_dist = 1.05)\n",
        "    a = coords\n",
        "    vecs = similar(a)\n",
        "    d = similar(a, 1, size(a, 2))\n",
        "    v = similar(d)\n",
        "    res = []\n",
        "    for x_i in eachcol(x)\n",
        "        vecs .= (x_i .- a).^2\n",
        "        sum!(d, vecs)                               # d = sqdists(x_i, a)\n",
        "        d .= .-sqrt.(d)                             # d = -dists(x_i, a)\n",
        "        v .= d ./ radii'\n",
        "        L = lsumexp(v)                              # L = logsumexp(-dists(x_i, a) / radii)\n",
        "        d .= exp.(d)                                # d = exp.(-dists(x_i, a))\n",
        "        σ = dot(d, radii') / sum(d)                 # σ = smoothed mean atom radius weighted by exp(-dists)\n",
        "        push!(res, -σ*L)\n",
        "    end\n",
        "    return res .- ideal_dist\n",
        "end\n",
        "\n",
        "\n",
        "# memory heavy but correct\n",
        "function heavy_sdf(x, coords, radii; ideal_dist = 1.05)\n",
        "    sqdists = sum((reshape(x, 3, :, 1) .- reshape(coords, 3, 1, :)).^2; dims=1)\n",
        "    dists = sqrt.(dropdims(sqdists; dims=1))\n",
        "    expneg_dists= exp.(-dists)\n",
        "    softavg_nbhrad = sum(expneg_dists .* radii'; dims=2) ./ sum(expneg_dists; dims=2)\n",
        "\n",
        "    return vec(-softavg_nbhrad .* lsumexp(-dists ./ radii'; dims=2) .- ideal_dist)\n",
        "end\n",
        "\n",
        "#∇ₓSDF - low memory - to make faster should operate in bigger batches of columns over x\n",
        "function grad_sdf(x, coords, radii)\n",
        "    a = coords\n",
        "    vecs = similar(a)\n",
        "    d = similar(a, 1, size(a, 2)) # -dists\n",
        "    ed = similar(d) # exp(-dists)\n",
        "    nd = similar(d) # -dists(x_i, a) / radii (normalized dists by radius)\n",
        "    grads = similar(x)\n",
        "\n",
        "    for (i, x_i) in enumerate(eachcol(x))\n",
        "        vecs .= (x_i .- a).^2\n",
        "        sum!(d, vecs)                               # d = sqdists(x_i, a)\n",
        "        d .= .-sqrt.(d)                             # d = -dists(x_i, a)\n",
        "        nd .= d ./ radii'                           # nd = -dists(x_i, a) / radii\n",
        "        ed .= exp.(d)                               # ed = exp(-dists)\n",
        "\n",
        "        L = lsumexp(nd)                             # L = logsumexp(-dists(x_i, a)/radii)\n",
        "        ϕ = sum(ed)\n",
        "        ψ = dot(ed, radii')\n",
        "        σ = ψ / ϕ\n",
        "\n",
        "        # add σ*∇L\n",
        "        vecs .= exp.(nd)  ./ (d .* radii') .* (x_i .- a)\n",
        "        @views grads[:, i] .= -σ * sum(vecs;dims=2) / exp(L)\n",
        "\n",
        "        # add ∇ϕ component\n",
        "        vecs .= (ed ./ d) .* (x_i .- a) # ∇ϕ component\n",
        "        @views grads[:, i] .-= -ψ * L * sum(vecs;dims=2) / ϕ^2\n",
        "\n",
        "        # add ∇ψ component\n",
        "        vecs .*= radii' # ∇ψ component\n",
        "        @views grads[:, i] .-= ϕ * L * sum(vecs;dims=2) / ϕ^2\n",
        "    end\n",
        "\n",
        "    return grads\n",
        "end\n",
        "\n",
        "# Profiling and correctness checks \n",
        "function check_sdf()\n",
        "    xx = rand(3, 4000)\n",
        "    c = rand(3, 2000)\n",
        "    r = rand(2000)\n",
        "\n",
        "    println(\"My sdf\")\n",
        "    @time sdf(xx, c, r)\n",
        "    println(\"Heavy sdf\")\n",
        "    @time heavy_sdf(xx, c, r)\n",
        "\n",
        "    @assert isapprox(sdf(xx, c, r), heavy_sdf(xx, c, r))\n",
        "\n",
        "    msd(x) = sum(heavy_sdf(x, c, r))\n",
        "    println(\"My grad\")\n",
        "    @time grad_sdf(xx, c, r)\n",
        "    println(\"Heavy grad\")\n",
        "    @time gradient(msd, xx)[1]\n",
        "\n",
        "    @assert isapprox(grad_sdf(xx, c, r), gradient(msd, xx)[1])\n",
        "end\n",
        "#check_sdf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V0jE4N7znivY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39minitial #samples 324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAttracting samples to surface via gradient descent\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 1: 0.19370858935230315\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 2: 0.12540116565950285\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 3: 0.08664582197545564\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 4: 0.06127822426842723\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 5: 0.04399845196317627\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 6: 0.03183763669924627\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 7: 0.022322739468219284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 8: 0.015596193537336952\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 9: 0.01169031235377825\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 10: 0.009135975242368552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m#samples left after distance cull: 308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m#samples left after trapped cull: 208\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m#samples left after subsampling: 207\n"
          ]
        }
      ],
      "source": [
        "function sample_surface(coords, radii; \n",
        "                        samples_per_atom=1, num_iters=10, step_size=3.0, error_margin=0.3,\n",
        "                        batch_size=2000)\n",
        "    A = size(coords, 2)\n",
        "    B = samples_per_atom\n",
        "\n",
        "    mysdf(p) = sdf(p, coords, radii)\n",
        "    mygrad_sdf(p) = grad_sdf(p, coords, radii)\n",
        "\n",
        "    # Step 1 - Sample point cloud around atoms\n",
        "    @info \"initial #samples \" * string(A*B)\n",
        "    x = rand(Normal(0.0, 1.0), 3, A, B) \n",
        "    x .= x .* radii' .+ coords\n",
        "    x = reshape(x, 3, :) # size(x) = (3, A*B)\n",
        "\n",
        "    # Step 2 - Bring points closer to surface by minimizing the squared sdf\n",
        "    #          via gradient descent\n",
        "    @info \"Attracting samples to surface via gradient descent\"\n",
        "    batches = collect(Iterators.partition(axes(x, 2), batch_size))\n",
        "    for i in 1:num_iters\n",
        "        #n.b. this could be done on the gpu and would be much faster\n",
        "        Threads.@threads for cols in batches\n",
        "            @views x_batch = x[:, cols]\n",
        "            x_batch .-= step_size .* mysdf(x_batch)' .* mygrad_sdf(x_batch) # grad(mse(sdf))\n",
        "        end\n",
        "        @info \"Loss at iter $i: \" * string(mean(mysdf(x).^2) / 2)\n",
        "    end\n",
        "\n",
        "    # Step 3 - Clean the samples\n",
        "\n",
        "    # Discard samples far away from the surface\n",
        "    mask = abs.(mysdf(x)) .< error_margin\n",
        "    x = x[:, mask]\n",
        "    @info \"#samples left after distance cull: \" * string(count(mask))\n",
        "\n",
        "    # Compute normals as gradient of surface implicit function (aka sdf)\n",
        "    normals = mygrad_sdf(x)\n",
        "    foreach(normalize!, eachcol(normals))\n",
        "\n",
        "    # Discard samples nested inside the protein \n",
        "    # i.e. if moving \"upwards\" by 4Å actually reduces the distance to the surface\n",
        "    mask = (mysdf(x .+ 4 .* normals) .- mysdf(x)) .> 0.5\n",
        "    x = x[:, mask]\n",
        "    normals = normals[:, mask]\n",
        "    @info \"#samples left after trapped cull: \" * string(count(mask))\n",
        "\n",
        "    # Step 4 - subsampling - make sure sampling was uniform in space\n",
        "    # For each cubic bin of size 0.5Å we keep one sample per cell\n",
        "\n",
        "    # technically this is not subsampling because it is deterministic and always chooses \n",
        "    # one point per grid; might give slightly biased results\n",
        "    grid_loc = floor.(Int, x)\n",
        "    unique_idx = unique(i -> grid_loc[:, i], 1:size(x, 2))\n",
        "    x = x[:, unique_idx]\n",
        "    normals = normals[:, unique_idx]\n",
        "    @info \"#samples left after subsampling: \" * string(length(unique_idx))\n",
        "\n",
        "    return x, normals\n",
        "end\n",
        "\n",
        "radii = RADII[types]\n",
        "x, normals = sample_surface(coords, radii);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Returns for each x_i in x the indices of the kth nearest points in coords and the \n",
        "# distances to them\n",
        "function knearest(x, coords; k=16)\n",
        "    vecs = similar(coords)\n",
        "    sqdists = similar(coords, size(coords, 2))\n",
        "    ids = Array{Integer}(undef, k, size(x, 2))\n",
        "    dists = similar(x, k, size(x, 2))\n",
        "    # hot loop\n",
        "    for (i, x_i) in enumerate(eachcol(x))\n",
        "        vecs .= (x_i .- coords).^2\n",
        "        sqdists .= dropdims(sum(vecs; dims=1);dims=1)                             \n",
        "        @views ids[:, i] .= sortperm(sqdists; alg=PartialQuickSort(k))[1:k]\n",
        "        @views dists[:, i] .= sqrt.(sqdists[ids[:, i]])\n",
        "    end\n",
        "    return ids, dists\n",
        "end\n",
        "\n",
        "nbh_atom_ids, dists = knearest(x, coords; k=8)\n",
        "\n",
        "t = reshape(types[vec(nbh_atom_ids)], size(nbh_atom_ids))\n",
        "t_onehot = onehotbatch(t, 1:6, 2)\n",
        "inv_dists = 1 ./ dists # size = 16 x num_samples\n",
        "\n",
        "labels = knearest(x, adp_coords; k=1)[2] .< 3.0\n",
        "\n",
        "count(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# geodesic distance\n",
        "\n",
        "function dists_dots(x, n, nbh_ids)\n",
        "    k = size(nbh_ids, 1)\n",
        "    vecs = similar(x, 3, k)\n",
        "    v = similar(x, k)\n",
        "    dists = similar(x, k, size(x, 2))\n",
        "    dots = similar(dists)\n",
        "    # hot loop\n",
        "    for i in axes(x, 2)\n",
        "        @views x_i = x[:, i]; n_i = n[:, i]\n",
        "        vecs .= (x_i .- x[:, nbh_ids[:, i]]).^2\n",
        "        v .= dropdims(sum(vecs; dims=1);dims=1)                             \n",
        "        @views dists[:, i] .= sqrt.(v)\n",
        "\n",
        "        vecs .= (n_i .* n[:, nbh_ids[:, i]])\n",
        "        v .= dropdims(sum(vecs; dims=1);dims=1)  \n",
        "        @views dots[:, i] .= v\n",
        "    end\n",
        "    return dists, dots\n",
        "end\n",
        "\n",
        "function quasi_geodesic_dist(x, n, nbh_ids; λ=1)\n",
        "    dists, dots = dists_dots(x, n, nbh_ids)\n",
        "\n",
        "    return dists .* (1 .+ λ .* (1 .- dots))\n",
        "end\n",
        "\n",
        "function my_geodesic_dist(x, n, nbh_ids)\n",
        "    dists, dots = dists_dots(x, n, nbh_ids)\n",
        "    clamp!(dots, -1.0+1e-14, 1.0-1e-14)\n",
        "    return dists .* acos.(dots) ./ sqrt.(2 .- 2 .* dots)\n",
        "end\n",
        "\n",
        "# Process dists so that they can be used inside the gaussian filter\n",
        "function gaussian_filter!(dists; σ=9)\n",
        "    dists .= exp.(.-dists.^2 ./ (2 .* σ^2))\n",
        "    return dists\n",
        "end\n",
        "\n",
        "nbh_ids, dists = knearest(x, x; k=100);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 3D geometry methods\n",
        "\n",
        "# Generate arbitrary local reference frames for each normal\n",
        "function nuv_from_n(n)\n",
        "    @views x = n[1, :]; y = n[2, :]; z = n[3, :]\n",
        "    s = sign.(z)\n",
        "    a = -1.0 ./ (s .+ z)\n",
        "    b = a .* x .* y\n",
        "\n",
        "    u = similar(n)\n",
        "    u[1, :] .= 1 .+ s .* a .* x .* x \n",
        "    u[2, :] .= s .* b \n",
        "    u[3, :] .= .- s .* x \n",
        "\n",
        "    v = similar(n)\n",
        "    v[1, :] .= b \n",
        "    v[2, :] .= s .+ a .* y .* y \n",
        "    v[3, :] .= .-y\n",
        "\n",
        "    nuv = cat(reshape(n, 3, 1, :) , reshape(u, 3, 1, :), reshape(v,3, 1,:); dims=2)\n",
        "    # size nuv = (3, 3, num_samples)\n",
        "    return nuv\n",
        "end\n",
        "\n",
        "# Compute positions of neighbours w.r.t local reference frames\n",
        "function local_pos(pos, frame, nbh_ids)\n",
        "    # size(frame, 1) = 3\n",
        "    k = size(frame, 2) # ∈ [1, 2, 3]\n",
        "    @views res = map(i -> frame[:, :, i]' * (pos[:, nbh_ids[:, i]] .- pos[:, i]),axes(pos, 2))\n",
        "    # size res[i] = (k, 3) * (3, nbh_size) = (k, nbh_size)\n",
        "\n",
        "    # for i in axes(x, 2)\n",
        "    #     @views x_i = x[:, i]\n",
        "    #     @views local_frame = nuv[:, :, i]\n",
        "    #     @views x_j = x[:, nbh_ids[:, i]]\n",
        "    #     push!(res, local_frame' * (x_j .- x_i)) # (3, 3) * (3, nbh_size) = (3, nbh_size)\n",
        "    # end\n",
        "\n",
        "    # final size: (k, nbh_size, num_samples)\n",
        "    return reshape(cat(res...;dims=2), k, size(nbh_ids, 1), size(pos, 2))\n",
        "end\n",
        "\n",
        "nuv = nuv_from_n(normals)\n",
        "local_pos(x, nuv, nbh_ids);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39minitial #samples 324\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAttracting samples to surface via gradient descent\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 1: 0.18391514102897097\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 2: 0.11200804421740201\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 3: 0.07919686823321234\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 4: 0.058603818255943664\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 5: 0.04469040299882387\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 6: 0.03278820777175682\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 7: 0.023812487786767422\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 8: 0.017212012556286533\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 9: 0.013739309098077964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss at iter 10: 0.011339167793507451\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m#samples left after distance cull: 302\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m#samples left after trapped cull: 224\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m#samples left after subsampling: 221\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0.722646 seconds (1.65 M allocations: 84.914 MiB, 4.87% gc time, 60.35% compilation time)\n"
          ]
        }
      ],
      "source": [
        "#@title Putting it all together\n",
        "function process_data_from_pdb(id::String; \n",
        "                               atom_nbh_size=8, ligand_bind_range=3.0)\n",
        "    struc = read(\"data/\" * id * \".pdb\", PDB)\n",
        "    atom_coords, atom_types, adp_coords = get_atom_data(struc)\n",
        "    atom_radii = RADII[atom_types]\n",
        "\n",
        "    # Sample oriented point cloud surface from atom metaball \n",
        "    pos, normals = sample_surface(atom_coords, atom_radii; num_iters=10)\n",
        "    nbh_atom_ids, atom_dists = knearest(pos, atom_coords; k=atom_nbh_size)\n",
        "\n",
        "    sample_types = reshape(atom_types[vec(nbh_atom_ids)], size(nbh_atom_ids))\n",
        "    types_onehot = onehotbatch(sample_types, 1:6, 2) \n",
        "    inv_dists = 1 ./ atom_dists # atom_nbh_size x num_samples\n",
        "\n",
        "    # 7 x atom_nbh_size x num_samples\n",
        "    feats = cat(types_onehot, reshape(inv_dists, 1, atom_nbh_size, :) ;dims=1)\n",
        "\n",
        "    labels = knearest(pos, adp_coords; k=1)[2] .< ligand_bind_range\n",
        "\n",
        "    # For tractability reasons, only convolve over the closest k samples w.r.t L2 distance\n",
        "    #nbh_surface_ids, _ = knearest(x, x; k=surface_nbh_size=300)\n",
        "    #weights = geodesic_dist(x, n, nbh_surface_ids)\n",
        "    #gaussian_filter!(weights)\n",
        "\n",
        "    return (pos=pos, normals=normals, feats=feats, labels=labels)\n",
        "end\n",
        "\n",
        "@time data = process_data_from_pdb(\"1AE4\");"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 2: Learning over the protein surface data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6×221 Matrix{Float32}:\n",
              " -0.440055  -0.422967  -0.43297   …  -0.422641  -0.414309  -0.430095\n",
              " -1.3341    -1.323     -1.32733      -1.32007   -1.31976   -1.32701\n",
              " -2.44653   -2.45781   -2.44399      -2.44898   -2.47146   -2.45105\n",
              "  0.938986   0.932628   0.9327        0.927933   0.933421   0.934243\n",
              " -2.93426   -2.92887   -2.92688      -2.92232   -2.9318    -2.92966\n",
              "  0.176727   0.183002   0.179153  …   0.182902   0.186374   0.180335"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Chemical Layer - compute chemical embedding of points based on surrounding atoms \n",
        "\n",
        "struct ChemicalLayer\n",
        "    atomMLP::Chain\n",
        "    sampleMLP::Chain\n",
        "end \n",
        "function ChemicalLayer(;input_dim=7, num_atoms=8, hidden_dim=12, emb_dim=6)\n",
        "    atomMLP = Chain(Dense(input_dim => hidden_dim),\n",
        "                    BatchNorm(num_atoms, leakyrelu),\n",
        "                    Dense(hidden_dim => emb_dim))\n",
        "    sampleMLP = Chain(Dense(emb_dim => hidden_dim),\n",
        "                      BatchNorm(hidden_dim, leakyrelu),\n",
        "                      Dense(hidden_dim => emb_dim))\n",
        "    return ChemicalLayer(atomMLP, sampleMLP)\n",
        "end\n",
        "function(m::ChemicalLayer)(x)\n",
        "    # Embed atoms in chemical space using an MLP\n",
        "    x = m.atomMLP(x)\n",
        "    # Aggregate for each sample, using a second MLP\n",
        "    x = dropdims(sum(x; dims=2);dims=2)\n",
        "    return m.sampleMLP(x)\n",
        "end\n",
        "\n",
        "Flux.@functor ChemicalLayer\n",
        "model = ChemicalLayer() |> gpu\n",
        "chem_emb = model(Float32.(data[:feats]) |> gpu) |> cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1×221 Matrix{Float32}:\n",
              " 0.196107  0.212117  0.201956  0.206608  …  0.211434  0.221096  0.205215"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Scalar field over protein surface\n",
        "# Projecting its gradient onto the tangent plane yields a smooth vector field \n",
        "# This ensures that the gauge of the manifold is smooth and consistent which is important,\n",
        "# because the convolution of the signal depends on the specific coordinate choice\n",
        "struct PotentialLayer\n",
        "    chain::Chain\n",
        "end \n",
        "function PotentialLayer(;input_dim=6, hidden_dim=16)\n",
        "    chain = Chain(Dense(input_dim => hidden_dim),\n",
        "                  BatchNorm(hidden_dim, leakyrelu),\n",
        "                  Dense(hidden_dim => hidden_dim),\n",
        "                  BatchNorm(hidden_dim, leakyrelu),\n",
        "                  Dense(hidden_dim => 1))\n",
        "    return PotentialLayer(chain)\n",
        "end\n",
        "function(m::PotentialLayer)(x)\n",
        "    return m.chain(x)\n",
        "end\n",
        "Flux.@functor PotentialLayer\n",
        "\n",
        "potmodel = PotentialLayer() |> gpu \n",
        "pot = potmodel(chem_emb |> gpu) |> cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "UndefVarError",
          "evalue": "UndefVarError: ConvLayer not defined",
          "output_type": "error",
          "traceback": [
            "UndefVarError: ConvLayer not defined\n",
            "\n",
            "Stacktrace:\n",
            " [1] top-level scope\n",
            "   @ d:\\ComputerScience\\Julia\\dMasif experiments\\dMasif_experiments.ipynb:1"
          ]
        }
      ],
      "source": [
        "function (m::ConvLayer)(emb, window, p_ij, nbh_ids)\n",
        "    # emb_ij = \n",
        "    @views emb_ij = cat(map(i -> emb[:, nbh_ids[:, i]], axes(emb, 2))...;dims=2)\n",
        "    p_ij_uv = local_pos(pos, uv, nbh_ids)\n",
        "    out = dropdims(sum(window .* m.localMLP(p_ij) .* emb_ij; dims=2);dims=2)\n",
        "    return out\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "update_nuv (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "function update_nuv(potentials, pos, nuv, nbh_ids, window)\n",
        "    num_samples = size(pos, 2)\n",
        "\n",
        "    window = reshape(window, 1, size(window)...)\n",
        "    # size window = (1, nbh_size, num_samples)\n",
        "\n",
        "    #pots_ij = p_j - p_i \n",
        "    # i.e. change of potential when going from i to j \n",
        "    ps = potentials\n",
        "    @views pots_ij = cat(map(i -> ps[:, nbh_ids[:, i]] .- ps[:, i], axes(pos, 2))...;dims=2)\n",
        "    pots_ij = reshape(pots_ij, 1, :, num_samples)\n",
        "    # size pots_ij = (1, nbh_size, num_samples)\n",
        "\n",
        "    #p_ij_uv gives location of pos_j w.r.t. the tangent plane of point i \n",
        "    @views p_ij_uv = local_pos(pos, nuv[:, 2:3, :], nbh_ids)\n",
        "    # size p_ij_uv = (2, nbh_size, num_samples)\n",
        "\n",
        "    # new_u sits in the (u,v) plane\n",
        "    new_u = dropdims(mean(window .* pots_ij .* p_ij_uv; dims=2);dims=2)\n",
        "    # size new_u = (2, num_samples)\n",
        "    # bring new_u to 3D => size = (3, num_samples)\n",
        "    new_u = vcat(zeros(Float32, 1, num_samples), new_u)\n",
        "\n",
        "    # rotate u counter clockwise by 90 degrees to get v\n",
        "    # rot by 90deg: (x, y) -> (-y, x)\n",
        "    @views new_v = vcat(zeros(Float32, 1, num_samples), -new_u[2, :]', new_u[1, :]')\n",
        "\n",
        "    new_uv = cat(reshape(new_u, 3, 1, :), reshape(new_v, 3, 1, :); dims=2)\n",
        "    # Finally, rotate new_u, new_v so that their normals match \n",
        "    # This amounts to reversing the local frame transformation\n",
        "    @views new_uv = map(i -> inv(nuv[:, :, i])' * new_uv[:, :, i],axes(pos, 2))\n",
        "    new_uv = reshape(cat(new_uv...;dims=2), 3, 2, num_samples)\n",
        "\n",
        "    @views n = reshape(nuv[:, 1, :], 3, 1, :)\n",
        "    new_nuv = cat(n, new_uv; dims=2)\n",
        "\n",
        "    return new_nuv\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(221,)\n"
          ]
        },
        {
          "ename": "ArgumentError",
          "evalue": "ArgumentError: number of columns of each array must match (got (221, 1, 1))",
          "output_type": "error",
          "traceback": [
            "ArgumentError: number of columns of each array must match (got (221, 1, 1))\n",
            "\n",
            "Stacktrace:\n",
            " [1] _typed_vcat(#unused#::Type{Float64}, A::Tuple{Matrix{Float32}, Vector{Float64}, SubArray{Float64, 1, Matrix{Float64}, Tuple{Int64, Base.Slice{Base.OneTo{Int64}}}, true}})\n",
            "   @ Base .\\abstractarray.jl:1634\n",
            " [2] typed_vcat\n",
            "   @ .\\abstractarray.jl:1648 [inlined]\n",
            " [3] vcat(::Matrix{Float32}, ::Vector{Float64}, ::SubArray{Float64, 1, Matrix{Float64}, Tuple{Int64, Base.Slice{Base.OneTo{Int64}}}, true})\n",
            "   @ Base .\\abstractarray.jl:1625\n",
            " [4] update_nuv(potentials::Matrix{Float32}, pos::Matrix{Float64}, nuv::Array{Float64, 3}, nbh_ids::Matrix{Integer}, window::Matrix{Float64})\n",
            "   @ Main d:\\ComputerScience\\Julia\\dMasif experiments\\dMasif_experiments.ipynb:27\n",
            " [5] (::DMasif)(pos::Matrix{Float64}, nuv::Array{Float64, 3}, feats::Array{Float64, 3}, nbh_ids::Matrix{Integer}, window::Matrix{Float64})\n",
            "   @ Main d:\\ComputerScience\\Julia\\dMasif experiments\\dMasif_experiments.ipynb:23\n",
            " [6] top-level scope\n",
            "   @ d:\\ComputerScience\\Julia\\dMasif experiments\\dMasif_experiments.ipynb:44"
          ]
        }
      ],
      "source": [
        "struct DMasif\n",
        "    chem_layer::ChemicalLayer\n",
        "    potential_layer::PotentialLayer\n",
        "    classifier_layer::Chain\n",
        "end\n",
        "\n",
        "function DMasif()\n",
        "    chem_layer = ChemicalLayer()\n",
        "    potential_layer = PotentialLayer()\n",
        "    classifier_layer = Chain(Dense(6 => 16),\n",
        "                             BatchNorm(16, leakyrelu),\n",
        "                             Dense(16 => 1))\n",
        "    return DMasif(chem_layer, potential_layer, classifier_layer)\n",
        "end\n",
        "\n",
        "\n",
        "function (m::DMasif)(pos, nuv, feats, nbh_ids, window)\n",
        "    # Compute embedding based on chemical properties\n",
        "    emb = m.chem_layer(feats)\n",
        "\n",
        "    # Update gauge based on gradient of potential\n",
        "    potentials = m.potential_layer(emb)\n",
        "    nuv = update_nuv(potentials, pos, nuv, nbh_ids, window)\n",
        "    \n",
        "    # Apply several quasi-geodesic convolutions to update embedding\n",
        "    p_ij = local_pos(pos, nuv, nbh_ids)\n",
        "\n",
        "    #emb = m.conv_layers(emb, window, p_ij, nbh_ids)\n",
        "\n",
        "    # Finally, classify point based on its embedding\n",
        "    out = m.classifier_layer(emb)\n",
        "    return out \n",
        "end\n",
        "Flux.@functor DMasif\n",
        "\n",
        "pos = data[:pos] \n",
        "nuv = nuv_from_n(data[:normals])\n",
        "feats = data[:feats]\n",
        "nbh_ids = copy(knearest(pos, pos; k=100)[1])\n",
        "window = quasi_geodesic_dist(pos, data[:normals], nbh_ids)\n",
        "gaussian_filter!(window)\n",
        "\n",
        "model = DMasif()\n",
        "affinity = model(pos, nuv, feats, nbh_ids, window) \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Julia 1.8.1",
      "language": "julia",
      "name": "julia-1.8"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
